{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from time import time, sleep\n",
    "import logging\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PAGE_URL = \"https://www.webuycars.co.za/buy-a-car?activeTypeSearch=[%22Vehicle%22]&Priced_Amount_Sort=%22desc%22\"\n",
    "SPECIFIED_PAGE_URL = MAIN_PAGE_URL + \"&page={page_number}\"\n",
    "CAR_PAGE_URL = \"https://www.webuycars.co.za/buy-a-car/{car_id}\"\n",
    "\n",
    "NUM_THREADS = 3\n",
    "LOAD_WAIT_TIMEOUT = 20\n",
    "SLEEP_TIME = 60  # 1 minute\n",
    "NUMBER_OF_PAGES_BEFORE_SLEEP = 5\n",
    "\n",
    "CARS_FILE = \"../data/cars.csv\"\n",
    "LOG_FILE = \"../logs/log.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_page_number() -> int:\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(MAIN_PAGE_URL)\n",
    "    while True:  # Wait for the pagination to load\n",
    "        try:\n",
    "            driver.find_element(By.CLASS_NAME, \"pagination\")\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "    last_page_link = (\n",
    "        driver.find_element(By.CLASS_NAME, \"pagination\")\n",
    "        .find_elements(By.TAG_NAME, \"li\")[-1]\n",
    "        .find_element(By.TAG_NAME, \"a\")\n",
    "    )\n",
    "    last_page_link.click()\n",
    "    last_page_number = driver.current_url.split(\"=\")[-1]\n",
    "    driver.quit()\n",
    "    return int(last_page_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car_ids(driver: webdriver.Chrome, page_number: int) -> list:\n",
    "    driver.get(SPECIFIED_PAGE_URL.format(page_number=page_number))\n",
    "    car_ids = []\n",
    "    start_time = time()\n",
    "    while True:  # Keep trying until the page loads\n",
    "        try:\n",
    "            driver.find_element(By.CLASS_NAME, \"no-results-message\")\n",
    "            return []\n",
    "        except:\n",
    "            pass\n",
    "        cars = driver.find_elements(By.CLASS_NAME, \"grid-card\")\n",
    "        if len(cars) > 0:\n",
    "            break\n",
    "        if time() - start_time > LOAD_WAIT_TIMEOUT:\n",
    "            raise TimeoutError(\"Page took too long to load\")\n",
    "    for car in cars:\n",
    "        car_id = car.find_element(\n",
    "            By.CSS_SELECTOR, \"button[aria-label='Add Favourite']\"\n",
    "        ).get_attribute(\"data-stocknumber\")\n",
    "        car_ids.append(car_id)\n",
    "    return car_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car_data(driver: webdriver.Chrome, car_id: str) -> dict:\n",
    "    driver.get(CAR_PAGE_URL.format(car_id=car_id))\n",
    "    start = time()\n",
    "    while (\n",
    "        len(driver.find_elements(By.CLASS_NAME, \"details-container\")) == 0\n",
    "    ):  # Keep trying until the page loads\n",
    "        if time() - start > LOAD_WAIT_TIMEOUT:\n",
    "            raise TimeoutError(\"Page load timeout\")\n",
    "        pass\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    car_data = {}\n",
    "    car_data[\"id\"] = car_id\n",
    "    details_containers = soup.find_all(\"div\", class_=\"details-container\")\n",
    "    for details in details_containers:\n",
    "        datas = details.find_all(\"div\", class_=\"flex-row\")\n",
    "        for data in datas:\n",
    "            key = data.find(\"div\").text\n",
    "            try:\n",
    "                value = data.find(\"strong\").text\n",
    "            except:\n",
    "                continue\n",
    "            if key[-1] == \":\":\n",
    "                key = key[:-1]\n",
    "            car_data[key] = value\n",
    "\n",
    "    features = []\n",
    "    try:\n",
    "        vehicle_features = soup.find(\n",
    "            \"h2\", string=\"VEHICLE FEATURES\"\n",
    "        ).next_sibling.find_all(\"div\", class_=\"chip-text m-1\")\n",
    "        for feature in vehicle_features:\n",
    "            features.append(feature.text)\n",
    "    except:\n",
    "        pass\n",
    "    car_data[\"Features\"] = features\n",
    "\n",
    "    try:\n",
    "        car_data[\"Price\"] = soup.find(\"div\", class_=\"price-text\").find(\"span\").text\n",
    "    except:\n",
    "        car_data[\"Price\"] = (\n",
    "            soup.find(\"div\", class_=\"wheel-text-middle\").find(\"span\").text\n",
    "        )\n",
    "    car_data[\"Dekra\"] = soup.find(\"img\", alt=\"dekra\").next_sibling.strip()\n",
    "    try:\n",
    "        car_data[\"Finance Price\"] = (\n",
    "            soup.find(\"div\", class_=\"finance-price\").find(\"span\").text\n",
    "        )\n",
    "    except:\n",
    "        car_data[\"Finance Price\"] = None\n",
    "\n",
    "    return car_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_car(\n",
    "    car_id: str, thread_id: int, car_queue: Queue, driver: webdriver.Chrome\n",
    ") -> bool:\n",
    "    failed = 0\n",
    "    while True:\n",
    "        try:\n",
    "            logging.info(f\"Thread {thread_id}: getting data for car {car_id}\")\n",
    "            car_data = get_car_data(driver, car_id)\n",
    "            car_queue.put(car_data)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"Thread {thread_id}: Error getting data for car {car_id}: {e}\"\n",
    "            )\n",
    "            if \"WebDriver session does not exist\" in str(e):\n",
    "                raise e\n",
    "            if failed == 3:\n",
    "                logging.error(\n",
    "                    f\"Thread {thread_id}: Failed to get data for car {car_id} 3 times, skipping\"\n",
    "                )\n",
    "                return False\n",
    "            else:\n",
    "                failed += 1\n",
    "                logging.error(f\"Thread {thread_id}: Retrying car {car_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(car_queue: Queue, i: int, end_page: int, thread_id: int):\n",
    "    logging.info(f\"Thread {thread_id}: started at index {i}\")\n",
    "    failed_ids = []\n",
    "    driver = webdriver.Chrome()\n",
    "    while True:\n",
    "        start_time = time()\n",
    "        page_number = NUM_THREADS * i + thread_id\n",
    "        if page_number > end_page:\n",
    "            logging.info(f\"Thread {thread_id}: finished\")\n",
    "            break\n",
    "        logging.info(f\"Thread {thread_id}: started page {page_number} (index {i})\")\n",
    "        try:\n",
    "            car_ids = get_car_ids(driver, page_number)\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"Thread {thread_id}: Error getting car ids for page {page_number}: {e}\"\n",
    "            )\n",
    "            if \"WebDriver session does not exist\" in str(e):\n",
    "                return\n",
    "            continue\n",
    "\n",
    "        for car_id in car_ids:\n",
    "            try:\n",
    "                if not handle_car(car_id, thread_id, car_queue, driver):\n",
    "                    failed_ids.append(car_id)\n",
    "            except Exception as e:\n",
    "                return\n",
    "        i += 1\n",
    "        logging.info(\n",
    "            f\"Thread {thread_id}: finished page {page_number} in {time()-start_time:.2f} seconds\"\n",
    "        )\n",
    "\n",
    "        if i % NUMBER_OF_PAGES_BEFORE_SLEEP == 0:\n",
    "            logging.info(\n",
    "                f\"Thread {thread_id}: scraped {NUMBER_OF_PAGES_BEFORE_SLEEP}, sleeping for {SLEEP_TIME} seconds\"\n",
    "            )\n",
    "            sleep(SLEEP_TIME)\n",
    "            logging.info(f\"Thread {thread_id}: woke up\")\n",
    "\n",
    "    for car_id in failed_ids:\n",
    "        try:\n",
    "            if not handle_car(car_id, thread_id, car_queue, driver):\n",
    "                logging.error(\n",
    "                    f\"Thread {thread_id}: Repeated failure for car {car_id}, skipping\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            return\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(cars: list[dict]):\n",
    "    with open(CARS_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        field_names = set()\n",
    "        for car in cars:\n",
    "            field_names.update(car.keys())\n",
    "        writer = csv.DictWriter(file, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for car in cars:\n",
    "            writer.writerow(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queue_to_list(queue: Queue) -> list:\n",
    "    result = []\n",
    "    while not queue.empty():\n",
    "        result.append(queue.get())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_queue = Queue()\n",
    "\n",
    "\n",
    "def main():\n",
    "    global car_queue\n",
    "\n",
    "    open(LOG_FILE, \"w\").close()\n",
    "    logging.basicConfig(\n",
    "        filename=LOG_FILE,\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] -> %(message)s\",\n",
    "    )\n",
    "\n",
    "    last_page_number = find_last_page_number()  # change this for testing\n",
    "    logging.info(f\"Starting scrape until page {last_page_number}\")\n",
    "    threads = []\n",
    "    start_time = time()\n",
    "    for i in range(NUM_THREADS):\n",
    "        thread = Thread(target=worker, args=(car_queue, 0, last_page_number, i + 1))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    logging.info(f\"Finished in {time()-start_time:.2f} seconds\")\n",
    "\n",
    "    cars = queue_to_list(car_queue)\n",
    "    write_to_csv(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
